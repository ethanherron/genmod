{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, os\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from einops import rearrange, repeat\n",
    "import copy\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "from modules.networks.unet import UNetModel\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"  # Use only the first GPU\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "tf = transforms.Compose([transforms.ToTensor()]) # mnist is already normalised 0 to 1\n",
    "train_dataset = MNIST(\"/data/edherron/data/MNIST\", train=True, download=False, transform=tf)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                           batch_size=256,\n",
    "                                           shuffle=True,\n",
    "                                           num_workers=1\n",
    "                                           )\n",
    "\n",
    "def pad(tensor):\n",
    "    return repeat(tensor, 'b -> b 1 1 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiffusionModel(nn.Module):\n",
    "    def __init__(self, model, device, num_timesteps=1000):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.model = model.to(self.device)\n",
    "        self.N = num_timesteps\n",
    "        \n",
    "        self.betas = self.linear_beta_schedule(self.N)\n",
    "        \n",
    "        self.beta_schedule = self.register_ddpm_schedules(self.betas)\n",
    "        \n",
    "        for k, v in self.beta_schedule.items():\n",
    "            self.register_buffer(k, v.to(self.device))\n",
    "        \n",
    "    def linear_beta_schedule(self, timesteps):\n",
    "        \"\"\"\n",
    "        linear schedule, proposed in original ddpm paper\n",
    "        \"\"\"\n",
    "        scale = 1000 / timesteps\n",
    "        beta_start = scale * 0.0015\n",
    "        beta_end = scale * 0.0155\n",
    "        return torch.linspace(beta_start, beta_end, timesteps, dtype = torch.float32)\n",
    "    \n",
    "    def register_ddpm_schedules(self, betas):\n",
    "        alphas = 1. - betas\n",
    "        alphas_cumprod = torch.cumprod(alphas, dim=0)\n",
    "        alphas_cumprod_prev = F.pad(alphas_cumprod[:-1], (1,0), value = 1.)\n",
    "        return {\n",
    "            'alphas': alphas,\n",
    "            'alphas_cumprod': alphas_cumprod,\n",
    "            'alphas_cumprod_prev': alphas_cumprod_prev,\n",
    "            'sqrt_alphas_cumprod': torch.sqrt(alphas_cumprod),\n",
    "            'sqrt_one_minus_alphas_cumprod': torch.sqrt(1. - alphas_cumprod),\n",
    "            'log_one_minus_alphas_cumprod': torch.log(1. - alphas_cumprod),\n",
    "            'sqrt_recip_alphas_cumprod': torch.sqrt(1. / alphas_cumprod),\n",
    "            'sqrt_recipm1_alphas_cumprod': torch.sqrt(1. / alphas_cumprod - 1.)\n",
    "        }\n",
    "        \n",
    "    def sample_forward_diffusion(self, x, t, noise):\n",
    "        x_t = (\n",
    "            self.sqrt_alphas_cumprod[t, None, None] * x\n",
    "            + self.sqrt_one_minus_alphas_cumprod[t, None, None] * noise\n",
    "        )\n",
    "        return x_t\n",
    "    \n",
    "    def get_train_tuple(self, batch):\n",
    "        x1 = batch.to(self.device)\n",
    "        x0 = torch.randn_like(x1).to(self.device)\n",
    "        t = torch.randint(1, self.N, (x1.shape[0],1)).to(self.device).long()\n",
    "        \n",
    "        xt = self.sample_forward_diffusion(x1, t, x0).to(self.device)\n",
    "        \n",
    "        return xt, t, x0\n",
    "    \n",
    "    def diffusion_model_loss(self, batch):\n",
    "        xt, t, x0 = self.get_train_tuple(batch)\n",
    "        \n",
    "        x0_prediction = self.model(xt, t.squeeze() / self.N)\n",
    "        \n",
    "        loss = F.mse_loss(x0, x0_prediction)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def reverse_diffusion_step(self, x_start, eps, timestep, timestep_next, eta):\n",
    "        noise = torch.randn_like(x_start).to(self.device)\n",
    "        alpha = self.alphas_cumprod[timestep]\n",
    "        alpha_next = self.alphas_cumprod[timestep_next]\n",
    "        sigma = eta * ((1 - alpha / alpha_next) * (1 - alpha_next) / (1 - alpha)).sqrt()\n",
    "        c = (1 - alpha_next - sigma ** 2).sqrt()\n",
    "        return x_start * alpha_next.sqrt() + c * eps + sigma * noise\n",
    "\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def sample_sde(self, batch, eta=1., num_inference_steps=None, inversion_strength=None, return_all_timesteps=False):\n",
    "        '''\n",
    "        DDIM sampling strategy for inference.\n",
    "        If num_inference_steps == number of training steps AND eta=1 then this is equivalent to \n",
    "        the original DDPM reverse diffusion process\n",
    "        '''\n",
    "        def get_x_0_hat(x_t, eps, t):\n",
    "            '''\n",
    "            get predicted final image from current image, x_t, and predicted noise, \\epsilon_{\\theta}(x_t, t).\n",
    "            '''\n",
    "            return (\n",
    "                self.sqrt_recip_alphas_cumprod[t] * x_t - \n",
    "                self.sqrt_recipm1_alphas_cumprod[t] * eps\n",
    "            )\n",
    "            \n",
    "        if num_inference_steps is None:\n",
    "            num_inference_steps = self.N\n",
    "            \n",
    "        timesteps = torch.linspace(-1, self.N - 1, steps = num_inference_steps + 1)\n",
    "        timesteps = list(reversed(timesteps.int().tolist()))\n",
    "        time_pairs = list(zip(timesteps[:-1], timesteps[1:]))\n",
    "        \n",
    "        x_i = torch.randn_like(batch).to(self.device)\n",
    "        imgs = [x_i]\n",
    "        for time, time_next in tqdm(time_pairs, desc='sampling loop time step'):\n",
    "            if inversion_strength is not None and time > round(inversion_strength * self.N):\n",
    "                continue\n",
    "\n",
    "            t_is = torch.tensor([time / self.N]).to(self.device)\n",
    "            t_is = t_is.repeat(batch.size(0))\n",
    "            \n",
    "            eps = self.model(x_i, t_is)\n",
    "            x_start = get_x_0_hat(x_i, eps, time)\n",
    "            \n",
    "            if time_next < 0:\n",
    "                img = x_start\n",
    "                imgs.append(img)\n",
    "                continue\n",
    "            \n",
    "            x_i = self.reverse_diffusion_step(x_start, eps, time, time_next, eta)\n",
    "            imgs.append(x_i)\n",
    "            \n",
    "        ret = img if not return_all_timesteps else torch.stack(imgs, dim = 1)      \n",
    "        \n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_diffusion_model(data_loader, diffusion_model, opt, device):\n",
    "    diffusion_model.model.train()\n",
    "    running_loss = 0.0\n",
    "    for data in data_loader:\n",
    "        x1, _ = data\n",
    "        x1 = x1.to(device)\n",
    "        \n",
    "        loss = diffusion_model.diffusion_model_loss(x1)\n",
    "        \n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        running_loss += loss.item()\n",
    "    avg_loss = running_loss / len(data_loader)\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters:  3607873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:30<04:35, 30.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss from epoch  0 :  0.30638152955377357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [01:01<04:06, 30.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss from epoch  1 :  0.019375035963318448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [01:32<03:37, 31.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss from epoch  2 :  0.01586703016482135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [02:04<03:08, 31.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss from epoch  3 :  0.015260628836744644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [02:37<02:38, 31.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss from epoch  4 :  0.01472900944979901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [03:09<02:08, 32.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss from epoch  5 :  0.014273841552277828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [03:42<01:37, 32.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss from epoch  6 :  0.013573538531806874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [04:15<01:05, 32.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss from epoch  7 :  0.013284055103963993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [04:48<00:32, 32.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss from epoch  8 :  0.012911408065639911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [05:21<00:00, 32.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss from epoch  9 :  0.012721095903915293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Init all of our models\n",
    "DM = DiffusionModel(UNetModel(), device)\n",
    "\n",
    "print(\"Number of parameters: \", sum(p.numel() for p in DM.model.parameters()))\n",
    "\n",
    "opt = torch.optim.Adam(DM.model.parameters(), lr=1e-4)\n",
    "\n",
    "for i in tqdm(range(10)):\n",
    "    loss_rec = train_diffusion_model(train_loader, DM, opt, device)\n",
    "    print('loss from epoch ', i, ': ', loss_rec)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "print(type(trajectory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1001, 1, 28, 28])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trajectory.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sampling loop time step:   0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sampling loop time step: 100%|██████████| 1000/1000 [00:17<00:00, 58.75it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x200 with 11 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch = torch.ones((1, 1, 28, 28))\n",
    "trajectory = DM.sample_sde(batch, return_all_timesteps=True)\n",
    "\n",
    "# Assuming `data_list` is your list of tensors\n",
    "fig, axs = plt.subplots(1, 11, figsize=(20, 2))  # Adjust figsize as needed\n",
    "\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    idx = i * 100  # Every 100th element\n",
    "    if idx < len(trajectory):\n",
    "        img = trajectory[0,idx, 0].detach().cpu().numpy()  # Reshape tensor to 28x28 for visualization\n",
    "        ax.imshow(img, cmap='gray')  # Plot as grayscale image\n",
    "        ax.set_title(f'Index {idx}')\n",
    "        ax.axis('off')\n",
    "    else:\n",
    "        ax.axis('off')  # Hide axes for plots beyond the list length\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

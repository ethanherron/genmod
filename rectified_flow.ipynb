{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, os\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from einops import rearrange\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from einops import rearrange, repeat\n",
    "\n",
    "from torchvision.utils import save_image, make_grid\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "from modules.networks.unet import UNetModel\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"  # Use only the first GPU\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "tf = transforms.Compose([transforms.ToTensor()]) # mnist is already normalised 0 to 1\n",
    "train_dataset = MNIST(\"/data/edherron/data/MNIST\", train=True, download=False, transform=tf)\n",
    "# val_dataset = MNIST(\"/data/edherron/data/MNIST\", train=False, download=False, transform=tf)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                           batch_size=256,\n",
    "                                           shuffle=True,\n",
    "                                           num_workers=1\n",
    "                                           )\n",
    "\n",
    "# val_loader = torch.utils.data.DataLoader(val_dataset, \n",
    "#                                         batch_size=256, \n",
    "#                                         shuffle=True, \n",
    "#                                         drop_last=True, \n",
    "#                                         num_workers=1\n",
    "#                                         )\n",
    "\n",
    "def pad(tensor):\n",
    "    return repeat(tensor, 'b -> b 1 1 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RectifiedFlow():\n",
    "    def __init__(self, model=None, device=None, num_steps=1000):\n",
    "        self.model = model\n",
    "        self.model.to(device)\n",
    "        self.N = num_steps\n",
    "        self.device = device\n",
    "        \n",
    "    def get_train_tuple(self, z0=None, z1=None):\n",
    "        t = torch.rand((z1.shape[0],)).to(self.device)\n",
    "        z_t = pad(t) * z1 + (1. - pad(t)) * z0\n",
    "        target = z1 - z0\n",
    "        return z_t, t, target\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def sample_ode(self, z0=None, N=None):\n",
    "        if N is None:\n",
    "            N = self.N\n",
    "        dt = 1./N\n",
    "        trajectory = []\n",
    "        z = z0.detach().clone().to(self.device)\n",
    "        \n",
    "        \n",
    "        trajectory.append(z.detach().clone())\n",
    "        for i in range(N):\n",
    "            t = torch.ones((z.shape[0],)) * i / N\n",
    "            t = t.to(self.device)\n",
    "            pred = self.model(z, t)\n",
    "            z = z.detach().clone() + pred * dt\n",
    "            \n",
    "            trajectory.append(z.detach().clone())\n",
    "        return trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_rectified_flow(data_loader, rectified_flow, opt, device):\n",
    "    rectified_flow.model.train()\n",
    "    running_loss = 0.0\n",
    "    for data in data_loader:\n",
    "        z1, _ = data\n",
    "        z1 = z1.to(device)\n",
    "        # z1 = rearrange(z1.to(device), 'b c h w -> b (c h w)')\n",
    "        z0 = torch.randn_like(z1).to(device)\n",
    "        \n",
    "        z_t, t, target = rectified_flow.get_train_tuple(z0, z1)\n",
    "        \n",
    "        pred = rectified_flow.model(z_t, t)\n",
    "        \n",
    "        loss = F.mse_loss(pred, target)\n",
    "        \n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        running_loss += loss.item()\n",
    "    avg_loss = running_loss / len(data_loader)\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters:  3607873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# Init all of our models\n",
    "model = UNetModel()\n",
    "RF = RectifiedFlow(model, device)\n",
    "\n",
    "print(\"Number of parameters: \", sum(p.numel() for p in model.parameters()))\n",
    "\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "for i in tqdm(range(50)):\n",
    "    loss_rec = train_rectified_flow(train_loader, RF, opt, device)\n",
    "    print('loss from epoch ', i, ': ', loss_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.randn((1,1,28,28))\n",
    "trajectory = RF.sample_ode(z0 = z)\n",
    "\n",
    "# Assuming `data_list` is your list of tensors\n",
    "fig, axs = plt.subplots(1, 11, figsize=(20, 2))  # Adjust figsize as needed\n",
    "\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    idx = i * 100  # Every 100th element\n",
    "    if idx < len(trajectory):\n",
    "        img = trajectory[idx].reshape(28, 28).detach().cpu().numpy()  # Reshape tensor to 28x28 for visualization\n",
    "        ax.imshow(img, cmap='gray')  # Plot as grayscale image\n",
    "        ax.set_title(f'Index {idx}')\n",
    "        ax.axis('off')\n",
    "    else:\n",
    "        ax.axis('off')  # Hide axes for plots beyond the list length\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.randn((10, 1, 28, 28))\n",
    "trajectories = [RF.sample_ode(z0=z[i].unsqueeze(0)) for i in range(10)]\n",
    "\n",
    "# Set up the plot for 10 rows of trajectories, each with 11 time steps (same as the column convention)\n",
    "fig, axs = plt.subplots(10, 11, figsize=(20, 20))  # Adjust figsize as needed, ensure there's enough space\n",
    "\n",
    "for row, trajectory in enumerate(trajectories):\n",
    "    for col, ax in enumerate(axs[row]):\n",
    "        idx = col * 100  # Every 100th element as in the original convention\n",
    "        if idx < len(trajectory):\n",
    "            img = trajectory[idx].reshape(28, 28).detach().cpu().numpy()  # Reshape tensor to 28x28 for visualization\n",
    "            ax.imshow(img, cmap='gray')  # Plot as grayscale image\n",
    "            ax.set_title(f'Index {idx}')\n",
    "            ax.axis('off')\n",
    "        else:\n",
    "            ax.axis('off')  # Hide axes for plots beyond the list length\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.randn((1, 1, 28, 28))\n",
    "trajectory = RF.sample_ode(z0 = z, N = 10)  # This should give a trajectory with 11 tensors including the initial condition\n",
    "\n",
    "# Assuming trajectory is your list of tensors with exactly 11 elements\n",
    "fig, axs = plt.subplots(1, 11, figsize=(20, 2))  # Adjust figsize as needed\n",
    "\n",
    "for idx, ax in enumerate(axs.flat):\n",
    "    if idx < len(trajectory):\n",
    "        img = trajectory[idx].reshape(28, 28).detach().cpu().numpy()  # Reshape tensor to 28x28 for visualization\n",
    "        ax.imshow(img, cmap='gray')  # Plot as grayscale image\n",
    "        ax.set_title(f'Step {idx}')\n",
    "        ax.axis('off')\n",
    "    else:\n",
    "        ax.axis('off')  # Hide axes for plots beyond the list length\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trajectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
